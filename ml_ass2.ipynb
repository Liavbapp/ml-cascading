{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0194deb7",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "daeae07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#sklearn\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Utils\n",
    "import random\n",
    "import os\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "\n",
    "# pretty table\n",
    "from prettytable import ALL as ALL\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "3eebeb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed():\n",
    "    random.seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3fa7bc",
   "metadata": {},
   "source": [
    "# Cascading Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7ae8eb-26eb-422d-b117-df2b082af61a",
   "metadata": {},
   "source": [
    "Basic implementation of the cascading meta learner using simple decision trees with various depths.\n",
    "for each sample, if the current model not confident with above 95% it passes it to the next model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "fa4d894e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CascadingTreeClassifier:\n",
    "    def __init__(self, cascading_depth, threshold):\n",
    "        self.depth = cascading_depth\n",
    "        self.threshold = threshold\n",
    "        self.trees = self.generate_trees(cascading_depth)\n",
    "        self.tree_counter = {i+1: 0 for i in range(cascading_depth)}\n",
    "        self.descison_counter = {i+1: 0 for i in range(cascading_depth)}\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_trees(cascading_depth):\n",
    "        trees = [DecisionTreeClassifier(max_depth=i, random_state=SEED+i) for i in range(1, cascading_depth + 1)]\n",
    "        return trees\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        _ = [t.fit(X, y) for t in self.trees]\n",
    "        return self\n",
    "\n",
    "\n",
    "    def predict_instance(self, x):\n",
    "        for i, tree in enumerate(self.trees):\n",
    "            confidence_arr = tree.predict_proba(x.reshape(1, - 1))\n",
    "            self.tree_counter[i + 1] += 1\n",
    "            if confidence_arr.max() > self.threshold:\n",
    "                self.descison_counter[i+1] += 1\n",
    "                return confidence_arr\n",
    "        \n",
    "        self.descison_counter[i+1] += 1\n",
    "        return confidence_arr\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        predictions = np.apply_along_axis(func1d=self.predict_instance, axis=1, arr=X)\n",
    "        predictions = np.squeeze(predictions, axis=1)\n",
    "        return predictions\n",
    "\n",
    "    def predict(self, X):\n",
    "        proba_pred = self.predict_proba(X)\n",
    "        classes_pred = np.argmax(proba_pred, axis=1)\n",
    "        return classes_pred\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0487d879-9589-4f4a-81e4-c226c21b6d5d",
   "metadata": {},
   "source": [
    "generate_batch_indices will generate a slices of a given range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "fd737fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch_indices(X_len, batch_num, op, y=None):\n",
    "    batches = []\n",
    "    idxs = set()\n",
    "    \n",
    "    batch_size = np.ceil(X_len / (batch_num - (batch_num - 1) * op)).astype(int)\n",
    "    \n",
    "    if y is None: # features splitting\n",
    "        \n",
    "        for _ in range(batch_num):\n",
    "            b = []\n",
    "            b_size_left = batch_size\n",
    "\n",
    "            if len(idxs) < batch_size:\n",
    "                b = list(idxs)\n",
    "                b_size_left -= len(idxs)\n",
    "                idxs = set()\n",
    "                \n",
    "            if not idxs:\n",
    "                idxs = set(range(X_len))\n",
    "\n",
    "            b += random.sample(idxs, b_size_left)\n",
    "            batches.append(b)\n",
    "\n",
    "            idxs = idxs - set(b)\n",
    "    \n",
    "        return batches\n",
    "        \n",
    "    else: # data splitting\n",
    "        skf = StratifiedKFold(n_splits=batch_num, shuffle=True, random_state=SEED)\n",
    "        X = np.arange(X_len)\n",
    "        for others_indices, batch_indices in skf.split(X, y):\n",
    "            num_to_choose = batch_size - len(batch_indices)\n",
    "            batches.append(np.concatenate([batch_indices, np.random.choice(others_indices, num_to_choose, replace=False)]))\n",
    "            \n",
    "        return batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11dbcbd9-37e8-42da-a124-ba9526e25378",
   "metadata": {},
   "source": [
    "#  Changes to the basic implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ce70b8-65c5-4671-a1fa-283b9ed0165b",
   "metadata": {},
   "source": [
    "We are suggesting 3 changes to the basic implementation:\n",
    " - AdvancedCascadingTreeClassifier: each tree was trained on a different slice from the data with overlapping between slices\n",
    " - FeatureCascadingTreeClassifier: each tree was trained on a different slice from the features with overlapping between slices\n",
    " - CombineCascadingTreeClassifier: each tree was trained on both different data and different features with overlapping between slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "bbe50480",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvancedCascadingTreeClassifier(CascadingTreeClassifier):\n",
    "    def __init__(self, cascading_depth, threshold, overlapping_percentage):\n",
    "        super().__init__(cascading_depth, threshold)\n",
    "        self.overlapping_percentage = overlapping_percentage\n",
    "\n",
    "    def fit(self, X, y):        \n",
    "        batch_indices = generate_batch_indices(X.shape[0], self.depth, self.overlapping_percentage, y)\n",
    "        \n",
    "        for i, tree in enumerate(self.trees):\n",
    "            tree.fit(X[batch_indices[i],:], y[batch_indices[i]])\n",
    "            \n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "c262ae14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureCascadingTreeClassifier(CascadingTreeClassifier):\n",
    "    def __init__(self, cascading_depth, threshold, overlapping_percentage):\n",
    "        super().__init__(cascading_depth, threshold)\n",
    "        self.overlapping_percentage = overlapping_percentage\n",
    "        \n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.feature_indices = generate_batch_indices(X.shape[1], self.depth, self.overlapping_percentage)\n",
    "        \n",
    "        \n",
    "        for i, tree in enumerate(self.trees):\n",
    "            tree.fit(X[:,self.feature_indices[i]], y)\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def predict_instance(self, x):\n",
    "        for i, tree in enumerate(self.trees):\n",
    "            confidence_arr = tree.predict_proba(x[self.feature_indices[i]].reshape(1, - 1))\n",
    "            self.tree_counter[i + 1] += 1\n",
    "            if confidence_arr.max() > self.threshold:\n",
    "                self.descison_counter[i+1] += 1\n",
    "                return confidence_arr\n",
    "        \n",
    "        self.descison_counter[i+1] += 1\n",
    "        return confidence_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "871f5ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombineCascadingTreeClassifier(CascadingTreeClassifier):\n",
    "    def __init__(self, cascading_depth, threshold, overlapping_percentage):\n",
    "        super().__init__(cascading_depth, threshold)\n",
    "        self.overlapping_percentage = overlapping_percentage\n",
    "        \n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.feature_indices = generate_batch_indices(X.shape[1], self.depth, self.overlapping_percentage)\n",
    "        batch_indices = generate_batch_indices(X.shape[0], self.depth, self.overlapping_percentage, y)\n",
    "\n",
    "        for i, tree in enumerate(self.trees):\n",
    "            tree.fit(X.take(batch_indices[i], axis=0).take(self.feature_indices[i], axis=1), y[batch_indices[i]])\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def predict_instance(self, x):\n",
    "        for i, tree in enumerate(self.trees):\n",
    "            confidence_arr = tree.predict_proba(x[self.feature_indices[i]].reshape(1, - 1))\n",
    "            self.tree_counter[i + 1] += 1\n",
    "            if confidence_arr.max() > self.threshold:\n",
    "                self.descison_counter[i+1] += 1\n",
    "                return confidence_arr\n",
    "        \n",
    "        self.descison_counter[i+1] += 1\n",
    "        return confidence_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff6961b-d84e-4ec6-be6c-ef77ebbcb2cb",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3ac50d-b90c-4131-871f-ad8ff9959788",
   "metadata": {},
   "source": [
    "The evaluate function extract x,y from datasets and train on the different classifiers. \n",
    "It returns for each classifier the minimal log loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "bb588bc4-1dfc-4e66-bbfc-be03be3b54bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(extract_X_y):\n",
    "    \n",
    "    # prepare train/test\n",
    "    X,y = extract_X_y()\n",
    "    y =  LabelEncoder().fit_transform(y)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED, stratify=y)\n",
    "    \n",
    "    \n",
    "    eval_reuslts = {}\n",
    "    # vanila cdt evaluate\n",
    "    set_seed()\n",
    "    cdt = CascadingTreeClassifier(15, 0.95)\n",
    "    test_acc, test_loss, train_acc, train_loss = evaluate_by_cdt(cdt, X_train, X_test, y_train, y_test)\n",
    "    eval_reuslts.update({'vanila_test_acc': test_acc, 'vanila_test_loss': test_loss, 'vanila_train_acc': train_acc, 'vanila_train_loss': train_loss})\n",
    "    \n",
    "    min_test_loss = np.inf\n",
    "    for op in np.arange(0.85, 0.99, 0.01):\n",
    "        # cdt advanced, overlapping data\n",
    "        set_seed()\n",
    "        cdt_advanced = AdvancedCascadingTreeClassifier(15, 0.95, op)\n",
    "        test_acc, test_loss, train_acc, train_loss =  evaluate_by_cdt(cdt_advanced, X_train, X_test, y_train, y_test)\n",
    "        if test_loss < min_test_loss:\n",
    "            eval_reuslts.update({'advanced_test_acc': test_acc, 'advanced_test_loss': test_loss, 'advanced_train_acc': train_acc, 'advanced_train_loss': train_loss})\n",
    "            min_test_loss = test_loss\n",
    "    \n",
    "    min_test_loss = np.inf\n",
    "    for op in np.arange(0.85, 0.99, 0.01):\n",
    "        # cdt by features\n",
    "        set_seed()\n",
    "        cdt_features = FeatureCascadingTreeClassifier(15, 0.95, 0.95)\n",
    "        test_acc, test_loss, train_acc, train_loss = evaluate_by_cdt(cdt_features, X_train, X_test, y_train, y_test)\n",
    "        if test_loss < min_test_loss:\n",
    "            eval_reuslts.update({'features_test_acc': test_acc, 'features_test_loss': test_loss, 'features_train_acc': train_acc, 'features_train_loss': train_loss})\n",
    "            min_test_loss = test_loss\n",
    "            \n",
    "    min_test_loss = np.inf\n",
    "    for op in np.arange(0.85, 0.99, 0.01):\n",
    "        #  cdt combined, combination of cdt_features + cdt_advanced\n",
    "        set_seed()\n",
    "        cdt_combine = CombineCascadingTreeClassifier(15, 0.95, 0.98)\n",
    "        test_acc, test_loss, train_acc, train_loss = evaluate_by_cdt(cdt_combine, X_train, X_test, y_train, y_test)\n",
    "        if test_loss < min_test_loss:\n",
    "            eval_reuslts.update({'combined_test_acc': test_acc, 'combined_test_loss': test_loss, 'combined_train_acc': train_acc, 'combined_train_loss': train_loss})\n",
    "            min_test_loss = test_loss\n",
    "    return eval_reuslts\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "5349a2dd-645e-46c6-97b2-0bcd2b8002c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_by_cdt(cdt, X_train, X_test, y_train, y_test):\n",
    "    cdt.fit(X_train, y_train)\n",
    "    train_probs, train_preds, test_probs, test_preds  = cdt.predict_proba(X_train), cdt.predict(X_train), cdt.predict_proba(X_test),  cdt.predict(X_test)\n",
    "    \n",
    "    test_acc, test_loss= accuracy_score(y_test, test_preds), log_loss(y_test, test_probs)\n",
    "    train_acc, train_loss =  accuracy_score(y_train, train_preds), log_loss(y_train, train_probs)\n",
    "    \n",
    "    return test_acc, test_loss, train_acc, train_loss\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb6885a-7f86-4917-984d-89bf03503aa8",
   "metadata": {},
   "source": [
    "## Datasets Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f96de66-bc85-4c5f-8964-c442b6241ded",
   "metadata": {},
   "source": [
    "The various dataset we checked on the 4 classifiers. each function loads the data and pre-processes it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "167a6945-bdaf-4965-9efa-95949c7aab40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetal_health():\n",
    "    if not os.path.exists(r'./datasets/fetal_health.csv'):\n",
    "        !kaggle datasets download -d andrewmvd/fetal-health-classification  -f 'fetal_health.csv' -p './datasets/'\n",
    "    df_fetal = pd.read_csv(r'./datasets/fetal_health.csv')\n",
    "    X, y = df_fetal.iloc[:,:-1].values, df_fetal['fetal_health'].astype(int).values\n",
    "    \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "b712a934-ae49-471a-8c48-89bb37a3c484",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Frogs_MFCCs(): # \n",
    "    if not os.path.exists(r'./datasets/Frogs_MFCCs.csv'):\n",
    "        !wget 'https://archive.ics.uci.edu/ml/machine-learning-databases/00406/Anuran%20Calls%20(MFCCs).zip' -P './datasets/'\n",
    "        !unzip -q './datasets/Anuran Calls (MFCCs).zip' 'Frogs_MFCCs.csv' -d './datasets/' && rm './datasets/Anuran Calls (MFCCs).zip'\n",
    "\n",
    "    df_frogs = pd.read_csv(r'./datasets/Frogs_MFCCs.csv')\n",
    "    X = df_frogs.iloc[:, :22].values\n",
    "    y = df_frogs['Genus'].values\n",
    "    \n",
    "    return X,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "0cc791bb-6a5a-41d9-b9a1-fc8bf7754155",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avila(): # https://archive.ics.uci.edu/ml/machine-learning-databases/00459/\n",
    "    if not os.path.exists(r'./datasets/avila-tr.txt'):\n",
    "        !wget 'https://archive.ics.uci.edu/ml/machine-learning-databases/00459/avila.zip' -P './datasets/'\n",
    "        !unzip -q './datasets/avila.zip' 'avila/avila-tr.txt' -d './datasets/' && rm './datasets/avila.zip'\n",
    "        !mv './datasets/avila/avila-tr.txt' './datasets/avila-tr.txt' && rmdir './datasets/avila'\n",
    "\n",
    "    col_names = ['f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'Class']\n",
    "    df_avila = pd.read_csv(r'./datasets/avila-tr.txt', delimiter = \",\", names = col_names)\n",
    "    df_avila = df_avila[df_avila['Class'] != 'B']\n",
    "    X, y = df_avila.iloc[:,:-1].values, df_avila['Class'].values\n",
    "    \n",
    "    return X,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "1a421f42-3b7f-43df-a42f-f28dffcd3561",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log2(): # https://archive.ics.uci.edu/ml/machine-learning-databases/00542/\n",
    "    \n",
    "    if not os.path.exists(r'./datasets/log2.csv'):\n",
    "        !wget 'https://archive.ics.uci.edu/ml/machine-learning-databases/00542/log2.csv' -P './datasets/'\n",
    "\n",
    "\n",
    "    df_log2 = pd.read_csv(r'./datasets/log2.csv')\n",
    "    cols_order = list(df_log2.columns)\n",
    "    cols_order[-1], cols_order[cols_order.index('Action')] = cols_order[cols_order.index('Action')], cols_order[-1]\n",
    "    df_log2 = df_log2[cols_order]\n",
    "    X, y = df_log2.iloc[:,:-1].values, df_log2['Action'].values\n",
    "    X = MinMaxScaler().fit_transform(X)\n",
    "    \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "9203762d-3aca-4fd0-8b1a-c856839dbc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wine_quality_red(): # https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/\n",
    "    if not os.path.exists(r'./datasets/winequality-red.csv'):\n",
    "        !wget 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv' -P './datasets/'\n",
    "\n",
    "\n",
    "    df_wine_quality_red = pd.read_csv(r'./datasets/winequality-red.csv', delimiter=';')\n",
    "    X, y = df_wine_quality_red.iloc[:,:-1].values, df_wine_quality_red['quality'].values\n",
    "    X = MinMaxScaler().fit_transform(X)\n",
    "    \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "ad75db7e-f162-4591-89ca-716d116e28b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wine_quality_white(): # https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/\n",
    "    if not os.path.exists(r'./datasets/winequality-white.csv'):\n",
    "        !wget 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv' -P './datasets/'\n",
    "\n",
    "\n",
    "    df_wine_quality_white = pd.read_csv(r'./datasets/winequality-white.csv', delimiter=';')\n",
    "    df_wine_quality_white = df_wine_quality_white[df_wine_quality_white['quality'] != 9]\n",
    "    X, y = df_wine_quality_white.iloc[:,:-1].values, df_wine_quality_white['quality'].values\n",
    "    X = MinMaxScaler().fit_transform(X)\n",
    "    \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "e31f737b-4a3c-45cf-b636-91df0fd1f518",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CTG(): # https://archive.ics.uci.edu/ml/datasets/cardiotocography\n",
    "    if not os.path.exists(r'./datasets/CTG.xls'):\n",
    "        !wget 'https://archive.ics.uci.edu/ml/machine-learning-databases/00193/CTG.xls' -P './datasets/'\n",
    "\n",
    "\n",
    "    df_ctg = pd.read_excel(r'./datasets/CTG.xlsx')\n",
    "    X, y = df_ctg.iloc[:,:-1].values, df_ctg['CLASS'].values\n",
    "    X = MinMaxScaler().fit_transform(X)\n",
    "    \n",
    "    return X,y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "b093c797-1b13-4856-bd4f-1d5070040fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Dry_beans(): # https://archive.ics.uci.edu/ml/machine-learning-databases/00602/\n",
    "    if not os.path.exists(r'./datasets/Dry_Bean_Dataset.xlsx'):\n",
    "        !wget 'https://archive.ics.uci.edu/ml/machine-learning-databases/00602/DryBeanDataset.zip' -P './datasets/'\n",
    "        !unzip -q './datasets/DryBeanDataset.zip' 'DryBeanDataset/Dry_Bean_Dataset.xlsx' -d './datasets/' && rm './datasets/DryBeanDataset.zip'\n",
    "        !mv './datasets/DryBeanDataset/Dry_Bean_Dataset.xlsx' './datasets/Dry_Bean_Dataset.xlsx' && rmdir './datasets/DryBeanDataset'\n",
    "\n",
    "    df_dry_beans = pd.read_excel(r'./datasets/Dry_Bean_Dataset.xlsx')\n",
    "    X, y = df_dry_beans.iloc[:,:-1].values, df_dry_beans['Class'].values\n",
    "    X = MinMaxScaler().fit_transform(X)\n",
    "    \n",
    "    return X,y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ba39df-e270-4cac-8bc2-0e8fb19d0477",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Dry_beans(): # https://archive.ics.uci.edu/ml/machine-learning-databases/00241/\n",
    "    if not os.path.exists(r'./datasets/Dry_Bean_Dataset.xlsx'):\n",
    "        !wget 'https://archive.ics.uci.edu/ml/machine-learning-databases/00602/DryBeanDataset.zip' -P './datasets/'\n",
    "        !unzip -q './datasets/DryBeanDataset.zip' 'DryBeanDataset/Dry_Bean_Dataset.xlsx' -d './datasets/' && rm './datasets/DryBeanDataset.zip'\n",
    "        !mv './datasets/DryBeanDataset/Dry_Bean_Dataset.xlsx' './datasets/Dry_Bean_Dataset.xlsx' && rmdir './datasets/DryBeanDataset'\n",
    "\n",
    "    df_dry_beans = pd.read_excel(r'./datasets/Dry_Bean_Dataset.xlsx')\n",
    "    X, y = df_dry_beans.iloc[:,:-1].values, df_dry_beans['Class'].values\n",
    "    X = MinMaxScaler().fit_transform(X)\n",
    "    \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "b1980e45-8040-4c0c-9e65-82176e696fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Data_Cortex_Nuclear(): # https://archive.ics.uci.edu/ml/machine-learning-databases/00342/\n",
    "    if not os.path.exists(r'./datasets/Data_Cortex_Nuclear.xls'):\n",
    "        !wget 'https://archive.ics.uci.edu/ml/machine-learning-databases/00342/Data_Cortex_Nuclear.xls' -P './datasets/'\n",
    "\n",
    "    df_nuclear = pd.read_excel(r'./datasets/Data_Cortex_Nuclear.xls')\n",
    "    df_nuclear.drop(['MouseID', 'BAD_N', 'BCL2_N', 'pCFOS_N', 'H3AcK18_N', 'EGR1_N', 'H3MeK4_N', 'ELK_N', 'MEK_N', 'Bcatenin_N', 'Genotype', 'Treatment', 'Behavior'], axis=1, inplace=True)\n",
    "    df_nuclear.drop([987, 988, 989], axis=0, inplace=True)\n",
    "\n",
    "    X, y = df_nuclear.iloc[:,:-1].values, df_nuclear['class'].values\n",
    "    X = MinMaxScaler().fit_transform(X)\n",
    "    \n",
    "    return X,y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "7b4d7fa2-c907-4e6f-adee-f5485aa97b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def turkiye_student(): #h ttps://archive.ics.uci.edu/ml/machine-learning-databases/00262/\n",
    "    if not os.path.exists(r'./datasets/turkiye-student-evaluation_generic.csv'):\n",
    "        !wget 'https://archive.ics.uci.edu/ml/machine-learning-databases/00262/turkiye-student-evaluation_generic.csv' -P './datasets/'\n",
    "\n",
    "    df_students = pd.read_csv(r'./datasets/turkiye-student-evaluation_generic.csv')\n",
    "    cols_order = list(df_students.columns)\n",
    "    cols_order[-1], cols_order[cols_order.index('class')] = cols_order[cols_order.index('class')], cols_order[-1]\n",
    "    df_students = df_students[cols_order]\n",
    "#     df_students.drop(['instr'], axis=1, inplace=True)\n",
    "    X, y = df_students.iloc[:,:-1].values, df_students['class'].values\n",
    "#     X = MinMaxScaler().fit_transform(X)\n",
    "        \n",
    "    return X,y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e756841-ff5e-451a-a19e-63ff43aaf568",
   "metadata": {},
   "source": [
    "# Compare Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2167217-df11-4269-ae3d-758578e335e7",
   "metadata": {},
   "source": [
    "Running across all the datasets and computing loss and accuracy for both train and test. presenting the results in a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01fd507-ed58-4724-8ad8-6c8d1e4516ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf51e43d26f94e3587dfbbb977f423c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datasets = [fetal_health, Frogs_MFCCs, avila, log2, wine_quality_red, wine_quality_white, CTG, Dry_beans, Data_Cortex_Nuclear, turkiye_student]\n",
    "# datasets = [wine_quality_white]\n",
    "result_table = PrettyTable(hrules=ALL)\n",
    "# Leaves_sha_64\n",
    "\n",
    "result_table.field_names = ['Dataset',\n",
    "                            'Vanila_Acc', 'Vanila_Loss',\n",
    "                            'Advanced_Acc' , 'Advanced_loss',\n",
    "                            'Features_Acc' , 'Features_loss',\n",
    "                            'Combined_Acc' , 'Combined_loss']\n",
    "\n",
    "for dataset in tqdm(datasets):\n",
    "    result = evaluate(dataset)\n",
    "    result_table.add_row([dataset.__name__, '', '', '', '', '', '', '', ''])\n",
    "    \n",
    "    for key in result.keys():\n",
    "        if key.endswith('loss'):\n",
    "            result[key] = f'{result[key]:.4f}'\n",
    "        else:\n",
    "            result[key] = f'{result[key] * 100:.2f}%'\n",
    "    \n",
    "    BOLD = '\\033[1m'\n",
    "    BgCYAN = '\\033[46m'\n",
    "    BgORANGE = '\\033[43m'\n",
    "    END = '\\033[0m'\n",
    "\n",
    "    result_table.add_row(['train', result['vanila_train_acc'], result['vanila_train_loss'],\n",
    "                                   result['advanced_train_acc'], result['advanced_train_loss'],\n",
    "                                   result['features_train_acc'], result['features_train_loss'],\n",
    "                                   result['combined_train_acc'], result['combined_train_loss']])\n",
    "    \n",
    "    van_acc_test, van_loss_test = result ['vanila_test_acc'], result['vanila_test_loss']\n",
    "    adv_acc_test, adv_loss_test = result['advanced_test_acc'], result['advanced_test_loss']\n",
    "    fea_acc_test, fea_loss_test = result['features_test_acc'], result['features_test_loss']\n",
    "    comb_acc_test, comb_loss_test = result['combined_test_acc'], result['combined_test_loss']\n",
    "    \n",
    "    acc_scores = [van_acc_test, adv_acc_test, fea_acc_test, comb_acc_test]\n",
    "    acc_scores[np.argmax(acc_scores)] = BgCYAN + BOLD + acc_scores[np.argmax(acc_scores)] + END\n",
    "    loss_scores = [van_loss_test, adv_loss_test, fea_loss_test, comb_loss_test]\n",
    "    loss_scores[np.argmin(loss_scores)] = BgORANGE + BOLD + loss_scores[np.argmin(loss_scores)] + END\n",
    "    \n",
    "    result_table.add_row(['test', acc_scores[0], loss_scores[0],\n",
    "                                  acc_scores[1], loss_scores[1],\n",
    "                                  acc_scores[2], loss_scores[2],\n",
    "                                  acc_scores[3], loss_scores[3]])\n",
    "print(result_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b687e67f-57f8-4ed8-a132-e414ef3066c3",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2845c8-cc21-4f3f-89ad-b5fb9bc393af",
   "metadata": {},
   "source": [
    "As we can see the most of the upgraded classifiers achevied better performance over the vanila classifier version.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1590be-2dea-4285-b5c1-b9f3b63ba5e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "liav_env",
   "language": "python",
   "name": "liav_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
